{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits as pyfits\n",
    "from astropy import wcs\n",
    "import os, glob, sys\n",
    "import scipy.interpolate as scint\n",
    "import scipy.ndimage\n",
    "import scipy.optimize as scopt\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD: BIN DOWN IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://scipy.github.io/old-wiki/pages/Cookbook/Rebinning\n",
    "\n",
    "def congrid(a, newdims, method='linear', centre=False, minusone=False):\n",
    "    '''Arbitrary resampling of source array to new dimension sizes.\n",
    "    Currently only supports maintaining the same number of dimensions.\n",
    "    To use 1-D arrays, first promote them to shape (x,1).\n",
    "    \n",
    "    Uses the same parameters and creates the same co-ordinate lookup points\n",
    "    as IDL''s congrid routine, which apparently originally came from a VAX/VMS\n",
    "    routine of the same name.\n",
    "\n",
    "    method:\n",
    "    neighbour - closest value from original data\n",
    "    nearest and linear - uses n x 1-D interpolations using\n",
    "                         scipy.interpolate.interp1d\n",
    "    (see Numerical Recipes for validity of use of n 1-D interpolations)\n",
    "    spline - uses ndimage.map_coordinates\n",
    "\n",
    "    centre:\n",
    "    True - interpolation points are at the centres of the bins\n",
    "    False - points are at the front edge of the bin\n",
    "\n",
    "    minusone:\n",
    "    For example- inarray.shape = (i,j) & new dimensions = (x,y)\n",
    "    False - inarray is resampled by factors of (i/x) * (j/y)\n",
    "    True - inarray is resampled by(i-1)/(x-1) * (j-1)/(y-1)\n",
    "    This prevents extrapolation one element beyond bounds of input array.\n",
    "    '''\n",
    "    if not a.dtype in [np.float64, np.float32]:\n",
    "        a = np.cast[float](a)\n",
    "    \n",
    "    m1 = np.cast[int](minusone)\n",
    "    ofs = np.cast[int](centre) * 0.5\n",
    "    old = np.array( a.shape )\n",
    "    ndims = len( a.shape )\n",
    "    if len( newdims ) != ndims:\n",
    "        print \"[congrid] dimensions error. \" \\\n",
    "              \"This routine currently only support \" \\\n",
    "              \"rebinning to the same number of dimensions.\"\n",
    "        return None\n",
    "    newdims = np.asarray( newdims, dtype=float )    \n",
    "    dimlist = []\n",
    "\n",
    "    if method == 'neighbour':\n",
    "        for i in range( ndims ):\n",
    "            base = np.indices(newdims)[i]\n",
    "            dimlist.append( (old[i] - m1) / (newdims[i] - m1) \\\n",
    "                            * (base + ofs) - ofs )\n",
    "        cd = np.array( dimlist ).round().astype(int)\n",
    "        newa = a[list( cd )]\n",
    "        return newa\n",
    "    \n",
    "    elif method in ['nearest','linear']:\n",
    "        # calculate new dims\n",
    "        for i in range( ndims ):\n",
    "            base = np.arange( newdims[i] )\n",
    "            dimlist.append( (old[i] - m1) / (newdims[i] - m1) \\\n",
    "                            * (base + ofs) - ofs )\n",
    "        # specify old dims\n",
    "        olddims = [np.arange(i, dtype = np.float) for i in list( a.shape )]\n",
    "\n",
    "        # first interpolation - for ndims = any\n",
    "        mint = scipy.interpolate.interp1d( olddims[-1], a, kind=method )\n",
    "        newa = mint( dimlist[-1] )\n",
    "\n",
    "        trorder = [ndims - 1] + range( ndims - 1 )\n",
    "        for i in range( ndims - 2, -1, -1 ):\n",
    "            newa = newa.transpose( trorder )\n",
    "\n",
    "            mint = scipy.interpolate.interp1d( olddims[i], newa, kind=method )\n",
    "            newa = mint( dimlist[i] )\n",
    "\n",
    "        if ndims > 1:\n",
    "            # need one more transpose to return to original dimensions\n",
    "            newa = newa.transpose( trorder )\n",
    "\n",
    "        return newa\n",
    "    elif method in ['spline']:\n",
    "        oslices = [ slice(0,j) for j in old ]\n",
    "        oldcoords = np.ogrid[oslices]\n",
    "        nslices = [ slice(0,j) for j in list(newdims) ]\n",
    "        newcoords = np.mgrid[nslices]\n",
    "\n",
    "        newcoords_dims = range(np.rank(newcoords))\n",
    "        #make first index last\n",
    "        newcoords_dims.append(newcoords_dims.pop(0))\n",
    "        newcoords_tr = newcoords.transpose(newcoords_dims)\n",
    "        # makes a view that affects newcoords\n",
    "\n",
    "        newcoords_tr += ofs        \n",
    "\n",
    "        deltas = (np.asarray(old) - m1) / (newdims - m1)\n",
    "        newcoords_tr *= deltas\n",
    "\n",
    "        newcoords_tr -= ofs\n",
    "\n",
    "        newa = scipy.ndimage.map_coordinates(a, newcoords)\n",
    "        return newa\n",
    "    else:\n",
    "        print \"Congrid error: Unrecognized interpolation type.\\n\", \\\n",
    "              \"Currently only \\'neighbour\\', \\'nearest\\',\\'linear\\',\", \\\n",
    "              \"and \\'spline\\' are supported.\"\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD: READ APT POINTINGS FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readPointingFile(fname):\n",
    "    # READ APT POINTINGS FILE AND STRIP DITHERS/BASES:\n",
    "    \n",
    "    with open(fname) as f:\n",
    "        content = f.read().splitlines()\n",
    "    \n",
    "    # FIND WHERE EACH OBSERVATION STARTS IN THE POINTINGS FILE:\n",
    "    obs_start = [iline for iline in xrange(len(content)) if \"==============\" in content[iline]]\n",
    "    obs_start.append(len(content))\n",
    "    \n",
    "    # GET ALL THE DITHERS FOR EACH OF THE OBSERVATIONS:\n",
    "    dithers=[]\n",
    "    for iobs in xrange( len(obs_start[:-1]) ):\n",
    "        temp = content[obs_start[iobs]:obs_start[iobs+1]]\n",
    "        \n",
    "        temp = [x.split() for x in temp] # remove white spaces\n",
    "        temp = filter(None, temp) # remove empty lines\n",
    "    \n",
    "        temp = [x for x in temp if \"SCIENCE\" in x]\n",
    "    \n",
    "        target  = np.array(  [float(i) for i in temp[0][7:9]] )\n",
    "        dithers.append(np.array( [ [ (float(x[9])+float(x[11])), (-float(x[10])+float(x[12])) ] for x in temp] ) )\n",
    "\n",
    "    return target, np.array(dithers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHODS: CENTER PSF + GENERATE SEGMENT POSITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def centerPSF(image):\n",
    "    hdu = pyfits.open(image)\n",
    "    sci = hdu[1].data\n",
    "\n",
    "    com = scipy.ndimage.center_of_mass(sci) \n",
    "    com = [int(com[0]), int(com[1])]\n",
    "    mid = len(sci)/2\n",
    "        \n",
    "    PSF = np.roll(sci, mid-com[0], axis=0)\n",
    "    PSF = np.roll(PSF, mid-com[1], axis=1)\n",
    "    \n",
    "    PSF = np.asarray([PSF]*18)\n",
    "    \n",
    "    return PSF\n",
    "\n",
    "def read18PSF(image):\n",
    "    \n",
    "    hdu = pyfits.open(image)\n",
    "    PSF = hdu[0].data\n",
    "    \n",
    "    return PSF\n",
    "\n",
    "\n",
    "def get_boresight_offset(sigma):\n",
    "    return  np.random.normal(0., (sigma/np.sqrt(2)), (1,2))\n",
    "\n",
    "\n",
    "def get_segment_offset(sigma):\n",
    "    return np.random.normal(0., (sigma/np.sqrt(2)), (18,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHODS: ROTATE SCA/POINTS FOR PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_rotate_pts(points, rotation, dec):\n",
    "    # FOR PLOTTING PURPOSES:\n",
    "    temp = np.copy(points)\n",
    "    angle = rotation * np.pi/180.\n",
    "\n",
    "    points[:,0] = (temp[:,0]*np.cos(angle) - temp[:,1]*np.sin(angle) ) \n",
    "    points[:,1] = (temp[:,1]*np.cos(angle) + temp[:,0]*np.sin(angle) )\n",
    "    \n",
    "    points[:,0] /= np.cos(dec*np.pi/180.)\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def shift_rotate_SCA(SCA, radangle, target, dither):\n",
    "    xdith = dither[1]\n",
    "    ydith = dither[0]\n",
    "\n",
    "    tempSCA = np.copy(SCA)\n",
    "    tempSCA[:,0]= SCA[:,0]*np.cos(radangle) - SCA[:,1]*np.sin(radangle) \n",
    "    tempSCA[:,1]= SCA[:,0]*np.sin(radangle) + SCA[:,1]*np.cos(radangle)\n",
    "\n",
    "    xdith = dither[0]*np.sin(radangle) + dither[1]*np.cos(radangle)\n",
    "    ydith = dither[0]*np.cos(radangle) - dither[1]*np.sin(radangle)\n",
    "\n",
    "    xdith /= np.cos(target[1]*np.pi/180.)\n",
    "\n",
    "    SCA[:,0] = tempSCA[:,0] + target[1] + ydith/3600.\n",
    "    SCA[:,1] = tempSCA[:,1]/np.cos(target[1]*np.pi/180.) + target[0] + xdith/3600.\n",
    "            \n",
    "    return SCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASS: CREATE TILE OBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NRCtile():\n",
    "    \n",
    "        def __init__(self, target, rotation):   \n",
    "            \n",
    "            # ARCSECONDS:\n",
    "            SCAgap  = 5.\n",
    "            self.SCAwidth= 65.\n",
    "            MODgap  = 44.\n",
    "            MODwidth= SCAgap + 2.*self.SCAwidth\n",
    "            self.radangle = rotation *np.pi/180.\n",
    "\n",
    "            # DEFINE MIDDLE OF SCA's:\n",
    "            self.SCA = np.asarray([\n",
    "                [-MODwidth/2, +MODgap/2+MODwidth],              # A1\n",
    "                [+SCAgap/2,   +MODgap/2+MODwidth],              # A2\n",
    "                [-MODwidth/2, +MODgap/2+self.SCAwidth],         # A3\n",
    "                [+SCAgap/2,   +MODgap/2+self.SCAwidth],         # A4\n",
    "                [SCAgap/2,    -MODgap/2-self.SCAwidth-SCAgap],  # B1\n",
    "                [-MODwidth/2, -MODgap/2-self.SCAwidth-SCAgap],  # B2\n",
    "                [SCAgap/2,    -MODgap/2],                       # B3\n",
    "                [-MODwidth/2, -MODgap/2]                        # B4\n",
    "            ]) \n",
    "            self.SCA[:,0] += self.SCAwidth/2.\n",
    "            self.SCA[:,1] -= self.SCAwidth/2.\n",
    "            \n",
    "            # CONVERT TO DEGREES:\n",
    "            self.SCA[:,0]= self.SCA[:,0]/3600. \n",
    "            self.SCA[:,1]= self.SCA[:,1]/3600.\n",
    "        \n",
    "    \n",
    "        #\n",
    "        # THIS IS WHERE ALL THE MAGIC OF CREATING THE MOSAIC HAPPENS:\n",
    "        # \n",
    "        def assignWCS(self, iobs, idither, target, dither, dark, PSFcentered, segment_RADEC, bindim, seg_found, outdir, inputhistory):\n",
    "            # Defining function for finding center values:\n",
    "            linwcs = lambda x, y, n: ((x+y)/2)\n",
    "            \n",
    "            bindim = 300\n",
    "            dither = dither[::-1] \n",
    "            scaledSCAwidth = self.SCAwidth/np.cos(target[1]*np.pi/180.)\n",
    "            platescale = 0.032/3600. *(2048./bindim)\n",
    "            \n",
    "            SCA = shift_rotate_SCA(np.copy(self.SCA), self.radangle, target, dither)\n",
    "            \n",
    "            # LOOP OVER EACH SCA, ASSESS IF THERE SHOULD BE A PSF, ADD ONE IF NECESSARY ELSE USE A DARK:\n",
    "            iimg = 0\n",
    "            for isca in xrange( len(self.SCA) ):                \n",
    "                ipsf = 0\n",
    "                            \n",
    "                # DETERMINE RELEVANT WCS HEADER INFORMATION:\n",
    "                crvalY = SCA[isca,0] \n",
    "                crvalX = SCA[isca,1]            \n",
    "                cdeltaX, cdeltaY = -platescale, platescale\n",
    "                \n",
    "                w = wcs.WCS(naxis=2)                           # http://docs.astropy.org/en/latest/wcs/index.html\n",
    "                w.wcs.crpix = [bindim/2, bindim/2]             # what is the center pixel of the XY grid.\n",
    "                w.wcs.crval = [crvalX, crvalY]                 # what is the galactic coordinate of that pixel.                \n",
    "                w.wcs.cdelt = np.array([cdeltaX, cdeltaY])     # what is the pixel scale in lon, lat.\n",
    "                w.wcs.ctype = [\"RA---TAN-SIP\", \"DEC--TAN-SIP\"] # you determine if this is in fact a tangential projection \n",
    "                WCShdr = w.to_header()                         # write the HDU object WITH THE HEADER\n",
    "                                \n",
    "                cpa = np.cos(self.radangle)\n",
    "                spa = np.sin(self.radangle)\n",
    "                WCShdr[\"CD1_1\"] = cdeltaX * cpa\n",
    "                WCShdr[\"CD1_2\"] = cdeltaY * spa\n",
    "                WCShdr[\"CD2_1\"] =-cdeltaX * spa\n",
    "                WCShdr[\"CD2_2\"] = cdeltaY * cpa\n",
    "            \n",
    "\n",
    "                # OPEN DARK FITS FILE AND USE AS TEMPLATE:\n",
    "                fitsfile = dark \n",
    "                hdu = pyfits.open(fitsfile)\n",
    "                \n",
    "                sci = hdu[1].data/50.  #REDUCE THE ITM NOISE LEVEL IN DARKS\n",
    "                dq  = hdu[2].data\n",
    "                prihdr = hdu[0].header\n",
    "                scihdr = hdu[1].header\n",
    "                dqhdr  = hdu[2].header\n",
    "                                \n",
    "                # BIN DOWN THE IMAGES FOR QUIP TO BE ABLE TO HANDLE:\n",
    "                sci = congrid(sci, [bindim, bindim])\n",
    "                dq  = congrid(dq,  [bindim, bindim])\n",
    "\n",
    "\n",
    "                # RANDOMIZE THE DARK A BIT BY SHIFTING IT RANDOMLY:\n",
    "                dy, dx = np.random.randint(1,bindim, size=2)\n",
    "                sci = np.roll(sci, dy, axis=0) # I CAN'T GET THIS TO WORK FOR BOTH AXES AT ONCE:\n",
    "                sci = np.roll(sci, dx, axis=1)\n",
    "                \n",
    "                \n",
    "                nseg = 0\n",
    "                tempPSF = np.zeros( (len(sci), len(sci)) )\n",
    "                for iseg in xrange(len(segment_RADEC)):\n",
    "\n",
    "                    w = wcs.WCS( scihdr+WCShdr )\n",
    "                    px, py = w.wcs_world2pix(segment_RADEC[iseg][0], segment_RADEC[iseg][1], 1)\n",
    "                    # IS THERE A SEGMENT ON THAT SCA?\n",
    "                    if (0 < px < bindim) and (0< py < bindim): \n",
    "                    \n",
    "                        # MARK SEGMENT AS CAPTURED BY NIRCAM SCA:\n",
    "                        if seg_found[iseg]==0: seg_found[iseg]=1\n",
    "                        print \"Found Segment #{:d} on SCA ({:d}/18)\".format(iseg+1,np.count_nonzero(seg_found))\n",
    "                        ipsf  = iseg+1\n",
    "                        nseg += 1\n",
    "                        mid=len(sci)/2.\n",
    "                        \n",
    "                        # BACK OFF FROM SCA EDGE BY A FEW PIXELS TO AVOID ROLL OVER:\n",
    "                        xedge, yedge = int(0.03*bindim), int(0.03*bindim)\n",
    "                        if px < xedge:        px = xedge\n",
    "                        if px > bindim-xedge: px = bindim-xedge\n",
    "                        if py < yedge:        py = yedge\n",
    "                        if py > bindim-yedge: py = bindim-yedge                            \n",
    "\n",
    "                        PSF = congrid(PSFcentered[iseg], [bindim, bindim])\n",
    "\n",
    "                        # INJECT THE PSF WHERE IT OUGHT TO BE ON SCA:\n",
    "                        PSF = np.roll(PSF, int(np.round(py)-mid), axis=0)\n",
    "                        PSF = np.roll(PSF, int(np.round(px)-mid), axis=1) \n",
    "                            \n",
    "                        tempPSF += PSF\n",
    "\n",
    "                # IF WE STITCHED MORE THAN ONE PSF ON SAME SCA, NORMALIZE THE TOTAL COUNTS:\n",
    "                if nseg >= 1: sci = tempPSF/nseg\n",
    "                \n",
    "                \n",
    "                # UPDATE HEADER INFORMATION AND SAVE FILE: \n",
    "                prihdr[\"SUBSIZE1\"]=bindim*10\n",
    "                prihdr[\"SUBSIZE2\"]=bindim\n",
    "                prihdr[\"HISTORY\"] =inputhistory\n",
    "                \n",
    "                new_hdul = pyfits.HDUList()\n",
    "                new_hdul.append(pyfits.ImageHDU(header=prihdr+WCShdr))\n",
    "                new_hdul.append(pyfits.ImageHDU(sci, header=WCShdr, name='SCI'))   \n",
    "                new_hdul.append(pyfits.ImageHDU(dq , header=WCShdr, name='DQ'))   \n",
    "                filename = outdir+'test{:04d}.fits'.format(8*idither+iimg)\n",
    "                if ipsf !=0 : print '   -->', filename\n",
    "                new_hdul.writeto(filename, overwrite=True)     \n",
    "                hdu.close()\n",
    "                new_hdul.close()\n",
    "                \n",
    "                iimg+=1\n",
    "            \n",
    "            return seg_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER INPUTS: FILES & BINSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = np.random.randint(10000)\n",
    "#seed = 8471\n",
    "seed = 7397\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "# FIX SIZE OF DOWSAMPLED IMAGES; IN FLIGHT, THIS IS ACCOMPLISHED BY MOSAIC_CONGRID.IPYND\n",
    "bindim = 300\n",
    "\n",
    "\n",
    "imgdir       = \"/Users/lajoie/TEL/WFSC/tools/mosaic-simulator/\"\n",
    "pointingfile = \"1134_Mosaic.pointing.txt\"      # GET FROM APT\n",
    "seglocations = \"PSF_location.txt\"              # GOT FROM ACTON'S ITM; HOW DO WE GENERATE THAT OURSELVES?\n",
    "psffile      = imgdir+\"ITM-OnePSF.fits\"\n",
    "psf18file    = imgdir+\"ITM-18PSF.fits\"\n",
    "darkfile     = imgdir+\"ITM-Dark.fits\"\n",
    "\n",
    "\n",
    "# ARE WE USING A RANDOM DEPLOYMENT (ITM-OnePSF) OR PARTICULAR ITM STATE (ITM-18PSF; E.G. FOR REHEARSAL)?\n",
    "random_segs = True\n",
    "\n",
    "boresight_sigma = 17.   #3-sigma radial; arcminutes\n",
    "segments_sigma  = 16.   #3-sigma radial; arcminutes\n",
    "\n",
    "# THIS ANGLE MOVES THE NORTH/EAST AXES CW, OR THE MOSAIC CCW:\n",
    "rotation = np.random.uniform(0.0, 90.0)\n",
    "\n",
    "seg_found = np.zeros(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN: DRAW RANDOM SEGMENT/BORESIGHT OFFSETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(imgdir)\n",
    "\n",
    "target, dithers = readPointingFile(imgdir+pointingfile)\n",
    "print \"Target  :\",target\n",
    "print \"Rotation: \",rotation\n",
    "\n",
    "boresight_offset = get_boresight_offset(boresight_sigma/3.) \n",
    "\n",
    "if random_segs:\n",
    "    segment_offsets = get_segment_offset(segments_sigma/3.)\n",
    "else:\n",
    "    # READ ACTON'S ITM SEGMENT LOCATIONS INSTEAD:\n",
    "    x, y = np.loadtxt(seglocations, usecols=(1, 2), unpack=True)\n",
    "    x =-x*0.032/60.\n",
    "    y = y*0.032/60.\n",
    "    segment_offsets = np.asarray(zip(x,y))\n",
    "    segment_offsets = shift_rotate_pts(segment_offsets, -rotation, 0.)\n",
    "\n",
    "total_offsets = (boresight_offset + segment_offsets)/60.\n",
    "\n",
    "\n",
    "# THIS ADJUSTMENT, SEEN THROUGHOUT, IS TO ACCOUNT FOR THE FACT \n",
    "# THAT AS YOU GO HIGHER IN DECLINATION, A GIVEN ANGULAR \n",
    "# SEPARATION RESULTS IN A LARGER R.A. SEPARATION:\n",
    "total_offsets[:,0] /= np.cos(target[1]*np.pi/180.)\n",
    "segment_RADEC = target + total_offsets\n",
    "\n",
    "print len(dithers),'observations in APT file (dithers in arcseconds)'\n",
    "print \"Random seed is:\", seed, '\\n'\n",
    "print \"Boresight offset: \",boresight_offset\n",
    "\n",
    "inputhistory = {\"Target\": target, \"Rotation\": rotation, \"Random seed\": seed, \"Boresight\": boresight_offset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT DEPLOYED SEGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "for i in xrange(18):\n",
    "    plt.plot(segment_RADEC[i,0], segment_RADEC[i,1], 'ro', markersize=6)\n",
    "    plt.annotate(str(i+1), xy=(segment_RADEC[i,0], segment_RADEC[i,1]), fontsize=15, ha='center', va='bottom' )\n",
    "\n",
    "deltadeg = 0.26\n",
    "plt.xlim( target[0]-deltadeg/np.cos(target[1]*np.pi/180.), target[0]+deltadeg/np.cos(target[1]*np.pi/180.)  )\n",
    "plt.ylim( target[1]-deltadeg, target[1]+deltadeg )\n",
    "plt.axvline(x=target[0], color='black', linestyle='--')\n",
    "plt.axhline(y=target[1], color='black', linestyle='--')\n",
    "\n",
    "obs1width = 2.2*10./60.\n",
    "left  = obs1width/2. \n",
    "right =-obs1width/2. \n",
    "top   = obs1width/2.\n",
    "bottom=-obs1width/2.\n",
    "\n",
    "corners = np.array([ [left,top], [left, bottom], [right, bottom], [right, top], [left,top] ])\n",
    "corners = shift_rotate_pts(corners, -rotation, target[1]) + target\n",
    "\n",
    "plt.plot(corners[:,0], corners[:,1], color='red', linestyle='--') \n",
    "plt.plot(corners[3,0], corners[3,1], 'bo')\n",
    "\n",
    "plt.xlabel(\"RA\")\n",
    "plt.ylabel(\"DEC\")\n",
    "plt.gca().invert_xaxis()\n",
    "plt.title(\"Seed {:d}\".format(seed))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER INPUT: DECIDE WHICH OBSERVATION TO \"RUN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CHOOSE WHICH OTE-01 OBSERVATION TO EXECUTE (1 to 7):\n",
    "#       Obs 1: Central\n",
    "#       Obs 2: East\n",
    "#       Obs 3: West\n",
    "#       Obs 4: SouthEast\n",
    "#       Obs 5: SouthWest\n",
    "#       Obs 6: NorthEast\n",
    "#       Obs 7: NorthWest\n",
    "obs = 1\n",
    "\n",
    "#outdir       = 'Obs{:d}_test{:d}/'.format(obs, bindim)\n",
    "outdir       = 'Seed{:d}/Obs{:d}/'.format(seed,obs)\n",
    "if not os.path.isdir(outdir): os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN LOOP: EXECUTE THE SELECTED OBSERVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tile = NRCtile(target, rotation)\n",
    "\n",
    "obs_dithers = dithers[obs-1]\n",
    "print len(obs_dithers), \"pointings\"\n",
    "\n",
    "# THIS IS OUR DEFAULT PSF THAT WE STITCH ON THE MOSAIC WHERE THERE ARE SEGMENTS:\n",
    "if random_segs: \n",
    "    centeredPSF = read18PSF(psf18file) #centerPSF(psffile)\n",
    "else: \n",
    "    centeredPSF = read18PSF(psf18file)\n",
    "\n",
    "\n",
    "# FOR EACH DITHER POINT, CREATE IMAGES. IF A SEGMENT IS THERE, USE THE centeredPSF:\n",
    "for itile in xrange( len(obs_dithers) ):   \n",
    "    #print itile,obs_dithers[itile]\n",
    "    seg_found = tile.assignWCS(obs, itile, target, obs_dithers[itile], darkfile, centeredPSF, segment_RADEC, bindim, seg_found, outdir, inputhistory)\n",
    " \n",
    "    \n",
    "print \"\\nFOUND {:d} SEGMENTS\".format(np.count_nonzero(seg_found))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT FOUND/MISSING SEGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "for i in xrange(18):\n",
    "    if seg_found[i]==0: \n",
    "        plt.plot(segment_RADEC[i,0], segment_RADEC[i,1], 'ro', markersize=6)\n",
    "        plt.annotate(str(i+1), xy=(segment_RADEC[i,0], segment_RADEC[i,1]), fontsize=15, ha='center', va='bottom' )\n",
    "    if seg_found[i]==1: \n",
    "        plt.plot(segment_RADEC[i,0], segment_RADEC[i,1], 'go', markersize=6)\n",
    "        plt.annotate(str(i+1), xy=(segment_RADEC[i,0], segment_RADEC[i,1]), fontsize=15, ha='center', va='bottom')\n",
    "\n",
    "plt.plot(corners[:,0], corners[:,1], color='red', linestyle='--') \n",
    "plt.plot(corners[3,0], corners[3,1], 'bo')\n",
    "\n",
    "plt.axvline(x=target[0], color='black', linestyle='--')\n",
    "plt.axhline(y=target[1], color='black', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"RA\")\n",
    "plt.ylabel(\"DEC\")\n",
    "plt.gca().invert_xaxis()\n",
    "plt.title(\"Seed {:d}\".format(seed))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE QUIP OPERATION XML FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nfiles = len( glob.glob(outdir+\"/*.fits\") )\n",
    "print nfiles\n",
    "\n",
    "opsfile = outdir.split('/')[0]+'/ops_file_Obs{:d}.xml'.format(obs)\n",
    "f = open(opsfile,'w')\n",
    "\n",
    "f.write('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n')\n",
    "f.write('<QUIP_OPERATION_FILE xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" creator=\"WSS Executive\" time=\"16:22:40.093Z\" date=\"2017-06-14Z\" version=\"6.0.1\" operational=\"false\" xsi:noNamespaceSchemaLocation=\"/Users/lajoie/TEL/WSS-6.0.1/Software/schema/quip_operation_file.xsd\">\\n')\n",
    "f.write('    <CORRECTION_ID>R2017061401</CORRECTION_ID>\\n')\n",
    "f.write('    <OPERATION_TYPE>THUMBNAIL</OPERATION_TYPE>\\n')\n",
    "f.write('    <IMAGES>\\n')\n",
    "\n",
    "for i in xrange(nfiles):\n",
    "    f.write(\"       <IMAGE_PATH>{:s}{:s}{:04d}.fits</IMAGE_PATH>\\n\".format(imgdir+outdir,\"test\",i))\n",
    "    \n",
    "f.write( '       </IMAGES>\\n'    )\n",
    "f.write( '       <OUTPUT>\\n')\n",
    "f.write( '           <OUTPUT_DIRECTORY>{:s}quip/</OUTPUT_DIRECTORY>\\n'.format(imgdir))\n",
    "f.write( '           <LOG_FILE_PATH>{:s}quip/R2017061401_quip_activity_log.xml</LOG_FILE_PATH>\\n'.format(imgdir))\n",
    "f.write( '           <OUT_FILE_PATH>{:s}quip/R2017061401_quip_out.xml</OUT_FILE_PATH>\\n'.format(imgdir))\n",
    "f.write( '       </OUTPUT>\\n')\n",
    "\n",
    "f.write('</QUIP_OPERATION_FILE>\\n')\n",
    "\n",
    "f.close()\n",
    "if not os.path.isdir(imgdir+\"quip/\"): os.mkdir(imgdir+\"quip/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda]",
   "language": "python",
   "name": "Python [anaconda]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
